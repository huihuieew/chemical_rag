{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线上RAG应用pdf文档频繁更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用户将他们的PDF文档存储在磁盘的某个特定目录中，然后有一个定时任务来扫描此目录并从中的PDF文档构建知识库。\n",
    "\n",
    "对于增量更新，做hash指纹这一点毋庸置疑，但是hash的对象不能是文件了，而应该聚焦于真实存到知识库的数据: document.\n",
    "\n",
    "LangChain索引使用记录管理器(RecordManager)来跟踪写入矢量存储的文档。\n",
    "当索引内容时，为每个文档计算哈希值，并将以下信息存储在记录管理器中:\n",
    "文档hash(页面内容和元数据的散列)\n",
    "写时间\n",
    "源id——每个文档应该在其元数据中包含信息，以便我们确定该文档的最终来源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores.elasticsearch import ElasticsearchStore\n",
    "from langchain.indexes import SQLRecordManager, index\n",
    "\n",
    "\n",
    "collection_name = \"test_index\"\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = ElasticsearchStore(\n",
    "    es_url=\"http://localhost:9200\",\n",
    "    index_name=\"test_index\",\n",
    "    embedding=embedding)\n",
    "\n",
    "namespace = f\"elasticsearch/{collection_name}\"\n",
    "record_manager = SQLRecordManager(\n",
    "    namespace, db_url=\"sqlite:///record_manager_cache.sql\"\n",
    ")\n",
    "# record_manager.create_schema()\n",
    "\n",
    "doc1 = Document(page_content=\"kitty\", metadata={\"source\": \"kitty.txt\"})\n",
    "doc2 = Document(page_content=\"doggy\", metadata={\"source\": \"doggy.txt\"})\n",
    "doc3 = Document(page_content=\"doggy1\", metadata={\"source\": \"doggy.txt\"})\n",
    "\n",
    "def _clear():\n",
    "    \"\"\"Hacky helper method to clear content. See the `full` mode section to to understand why it works.\"\"\"\n",
    "    index(\n",
    "        [],\n",
    "        record_manager,\n",
    "        vectorstore,\n",
    "        cleanup=None,\n",
    "        source_id_key=\"source\")\n",
    "\n",
    "_clear()\n",
    "\n",
    "res = index(\n",
    "    [doc1, doc1, doc2],\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=None,\n",
    "    source_id_key=\"source\",\n",
    ")\n",
    "print(res)\n",
    "# {'num_added': 2, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}\n",
    "\n",
    "res = index(\n",
    "    [doc1, doc3],\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=None,\n",
    "    source_id_key=\"source\",\n",
    ")\n",
    "print(res)\n",
    "# {'num_added': 1, 'num_updated': 0, 'num_skipped': 1, 'num_deleted': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = index(\n",
    "    [doc1, doc1, doc2],\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"full\",\n",
    "    source_id_key=\"source\",\n",
    ")\n",
    "print(res)\n",
    "# {'num_added': 2, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}\n",
    "\n",
    "res = index(\n",
    "    [doc1, doc3],\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"full\",\n",
    "    source_id_key=\"source\",\n",
    ")\n",
    "print(res)\n",
    "# {'num_added': 1, 'num_updated': 0, 'num_skipped': 1, 'num_deleted': 1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incremental \"增量模式\"，最常用的一种模式\n",
    "_clear()\n",
    "\n",
    "res = index(\n",
    "    [doc1, doc1, doc2],\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")\n",
    "print(res)\n",
    "# {'num_added': 2, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}\n",
    "\n",
    "res = index(\n",
    "    [doc1, doc3],\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")\n",
    "print(res)\n",
    "# {'num_added': 1, 'num_updated': 0, 'num_skipped': 1, 'num_deleted': 1}\n",
    "\n",
    "res = index(\n",
    "    [doc1],\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")\n",
    "print(res)\n",
    "# {'num_added': 0, 'num_updated': 0, 'num_skipped': 1, 'num_deleted': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index(\n",
    "    docs_source: Union[BaseLoader, Iterable[Document]],\n",
    "    record_manager: RecordManager,\n",
    "    vector_store: VectorStore,\n",
    "    *,\n",
    "    batch_size: int = 100,\n",
    "    cleanup: Literal[\"incremental\", \"full\", None] = None,\n",
    "    source_id_key: Union[str, Callable[[Document], str], None] = None,\n",
    "    cleanup_batch_size: int = 1_000,\n",
    "):\n",
    "    ...\n",
    "\n",
    "    if isinstance(docs_source, BaseLoader):\n",
    "        try:\n",
    "            doc_iterator = docs_source.lazy_load()\n",
    "        except NotImplementedError:\n",
    "            doc_iterator = iter(docs_source.load())\n",
    "    else:\n",
    "        doc_iterator = iter(docs_source)\n",
    "\n",
    "    source_id_assigner = _get_source_id_assigner(source_id_key)\n",
    "\n",
    "    # Mark when the update started.\n",
    "    index_start_dt = record_manager.get_time()\n",
    "    num_added = 0\n",
    "    num_skipped = 0\n",
    "    num_updated = 0\n",
    "    num_deleted = 0\n",
    "     \n",
    "     \n",
    "    for doc_batch in _batch(batch_size, doc_iterator):\n",
    "        hashed_docs = list(\n",
    "            _deduplicate_in_order(\n",
    "                [_HashedDocument.from_document(doc) for doc in doc_batch]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        source_ids: Sequence[Optional[str]] = [\n",
    "            source_id_assigner(doc) for doc in hashed_docs\n",
    "        ]\n",
    "\n",
    "        ...\n",
    "\n",
    "        exists_batch = record_manager.exists([doc.uid for doc in hashed_docs])\n",
    "\n",
    "        # Filter out documents that already exist in the record store.\n",
    "        uids = []\n",
    "        docs_to_index = []\n",
    "         \n",
    "        # 判断哪些是要更新，哪些是要添加的\n",
    "        for hashed_doc, doc_exists in zip(hashed_docs, exists_batch):\n",
    "            if doc_exists:\n",
    "                # Must be updated to refresh timestamp.\n",
    "                record_manager.update([hashed_doc.uid], time_at_least=index_start_dt)\n",
    "                num_skipped += 1\n",
    "                continue\n",
    "            uids.append(hashed_doc.uid)\n",
    "            docs_to_index.append(hashed_doc.to_document())\n",
    "\n",
    "        # 知识入向量库\n",
    "        if docs_to_index:\n",
    "            vector_store.add_documents(docs_to_index, ids=uids)\n",
    "            num_added += len(docs_to_index)\n",
    "\n",
    "        # 更新数据库记录时间\n",
    "        record_manager.update(\n",
    "            [doc.uid for doc in hashed_docs],\n",
    "            group_ids=source_ids,\n",
    "            time_at_least=index_start_dt,\n",
    "        )\n",
    "\n",
    "        # 根据时间和source_ids 清理旧版本数据\n",
    "        if cleanup == \"incremental\":\n",
    "            ...\n",
    "\n",
    "            uids_to_delete = record_manager.list_keys(\n",
    "                group_ids=source_ids, before=index_start_dt\n",
    "            )\n",
    "            if uids_to_delete:\n",
    "                vector_store.delete(uids_to_delete)\n",
    "                record_manager.delete_keys(uids_to_delete)\n",
    "                num_deleted += len(uids_to_delete)\n",
    "\n",
    "    if cleanup == \"full\":\n",
    "        while uids_to_delete := record_manager.list_keys(\n",
    "            before=index_start_dt, limit=cleanup_batch_size\n",
    "        ):\n",
    "            # First delete from record store.\n",
    "            vector_store.delete(uids_to_delete)\n",
    "            # Then delete from record manager.\n",
    "            record_manager.delete_keys(uids_to_delete)\n",
    "            num_deleted += len(uidids_to_delete)\n",
    "\n",
    "    return {\n",
    "        \"num_added\": num_added,\n",
    "        \"num_updated\": num_updated,\n",
    "        \"num_skipped\": num_skipped,\n",
    "        \"num_deleted\": num_deleted,\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemical_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
