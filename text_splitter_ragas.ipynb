{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text切分\n",
    "# RAG分块策略之语义分块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed size chunking\n",
    "### Recursive Chunking\n",
    "### Document Specific Chunking\n",
    "### Semantic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'ArithmeticErrordddddddd'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "for text in texts:\n",
    "    splits.extend(text_splitter.split_text(text))\n",
    "splits[:5], len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_chunks = text_splitter.split_documents(documents)\n",
    "for chunk in naive_chunks[10:15]:\n",
    "    print(chunk.page_content+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = 'ddddd'\n",
    "\n",
    "semantic_chunker = SemanticChunker(embed_model, breakpoint_threshold_type=\"precentile\")\n",
    "\n",
    "semantic_chunks = semantic_chunker.create_documents([d.page_content for d in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "semantic_chunk_vectorstore = Chroma.from_documents(\n",
    "    documents=semantic_chunks,\n",
    "    embedding=embed_model,\n",
    "    persist_directory=\"./semantic_chunks\",\n",
    ")\n",
    "\n",
    "semantic_chunk_retriever = semantic_chunk_vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "semantic_chunk_retriever.invoke(\"Describe the Feature-based Approach with BERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_template = \"\"\"\n",
    "use the following context to answer the user's question, please response in chinese:\n",
    "    Context:\n",
    "    {content}\n",
    "    \n",
    "    -----\n",
    "    User's question:\n",
    "    {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatGroq = ''\n",
    "userdata = ''\n",
    "chat_model = ChatGroq(temperature=0,\n",
    "                      model_name=\"mixtral-8x7b-32768\",\n",
    "                      api_key=userdata.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "semantic_rag_chain = (\n",
    "    {\"context\": semantic_chunk_retriever, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | chat_model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "semantic_rag_chain.invoke(\"Describe the Feature-based Approach with BERT?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 语义块的Ragas评估比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False\n",
    ")\n",
    "\n",
    "synthetic_data_chunks = synthetic_data_splitter.create_documents([d.page_content for d in documents])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "ground_truths_semantic = []\n",
    "contexts = []\n",
    "answers = []\n",
    "\n",
    "question_template = \"\"\"\\\n",
    "    Given the following context, answer the question using only the context. If the answer is not contained within the context, say \"I don't know.\"\n",
    "    Context: {context}\n",
    "\"\"\"\n",
    "question_prompt = ChatPromptTemplate.from_template(question_template)\n",
    "\n",
    "ground_truth_template = \"\"\"\\\n",
    "    Given the following context, answer the question using only the context. If the answer is not contained within the context, say \"I don't know.\"\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "\"\"\"\n",
    "ground_truth_prompt = ChatPromptTemplate.from_template(ground_truth_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_chain = question_prompt | chat_model | StrOutputParser()\n",
    "ground_truth_chain = ground_truth_prompt | chat_model | StrOutputParser()\n",
    "\n",
    "for chunk in synthetic_data_chunks[10:20]:\n",
    "    questions.append(question_chain.invoke({\"context\": chunk.page_content}))\n",
    "    contexts.append(chunk.page_content)\n",
    "    ground_truths_semantic.append(ground_truth_chain.invoke({\"context\": chunk.page_content, \"question\": questions[-1]}))\n",
    "    answers.append(semantic_rag_chain.invoke(questions[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  将生成的内容格式化为HuggingFace数据集格式\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "qagc_list = []\n",
    "\n",
    "for question, answer, context, ground_truth in zip(questions, answers, contexts, ground_truths_semantic):\n",
    "    qagc_list.append({\"question\": question, \"answer\": answer, \"context\": context, \"ground_truth\": ground_truth})\n",
    "\n",
    "eval_dataset = Dataset.from_list(qagc_list)\n",
    "eval_dataset\n",
    "\n",
    "# Dataset({\n",
    "#     features: ['question', 'answer', 'context', 'ground_truth'],\n",
    "#     num_rows: 100\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实施Ragas指标并评估我们创建的数据集。\n",
    "\n",
    "from ragas.metrics import answer_relavancy, faithfulness, context_recall, context_precision\n",
    "from ragas import evaluate\n",
    "\n",
    "result = evaluate(\n",
    "    eval_dataset,\n",
    "    metrics=[answer_relavancy, faithfulness, context_recall, context_precision],\n",
    "    llm=chat_model,\n",
    "    embeddings=embed_model,\n",
    "    raise_exceptions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "\n",
    "result = evaluate(\n",
    "    eval_dataset,\n",
    "    metrics=[\n",
    "        \"answer_relevancy\",\n",
    "        \"context_relevancy\",\n",
    "        \"context_precision\",\n",
    "        \"context_f1\",\n",
    "    ]\n",
    ")\n",
    "result\n",
    "# {'context_precision': 1.0000, 'faithfulness': 0.8857, 'answer_relevancy': 0.9172, 'context_recall': 1.0000}\n",
    "result_df = result.to_pandas()\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Chunker的Ragas评估比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "questions = []\n",
    "ground_truths_semantic = []\n",
    "contexts = []\n",
    "answers = []\n",
    "\n",
    "for chunk in tqdm.tqdm(synthetic_data_chunks[10:20]):\n",
    "    questions.append(question_chain.invoke({\"context\": chunk.page_content}))\n",
    "    contexts.append([chunk.page_content])\n",
    "    ground_truths_semantic.append(ground_truth_chain.invoke({\"question\": questions[-1], \"context\": contexts[-1]}))\n",
    "    answers.append(naive_rag_chain.invoke(questions[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qagc_list = []\n",
    "\n",
    "for question, answer, context,ground_truth in zip(questions, answers, contexts,ground_truths_semantic):\n",
    "    qagc_list.append({\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"context\": context,\n",
    "        \"ground_truth\": ground_truth\n",
    "    })\n",
    "\n",
    "naive_eval_dataset = Dataset.from_list(qagc_list)\n",
    "naive_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_result = evaluate(\n",
    "    naive_eval_dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relavancy\n",
    "    ]\n",
    ")\n",
    "naive_result\n",
    "\n",
    "# {'context_precision': 1.0000, 'faithfulness': 0.9500, 'answer_relevancy': 0.9182, 'context_recall': 1.0000}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemical_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
